{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BoltzmannMachine(nn.Module):\n",
    "    def __init__(self, n_visible, n_hidden):\n",
    "        super(BoltzmannMachine, self).__init__()\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        total = n_visible + n_hidden\n",
    "        self.W = nn.Parameter(torch.randn(total, total))\n",
    "        self.b = nn.Parameter(torch.randn(total))\n",
    "    \n",
    "    def energy(self, v, h):\n",
    "        v_h = torch.cat([v, h], 1)\n",
    "        self_energy = - torch.matmul(v_h, self.b)\n",
    "        cross_energy = - torch.matmul(v_h, torch.matmul(self.W, v_h.t()))\n",
    "        return self_energy + cross_energy\n",
    "\n",
    "    def forward(self, v):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_visible, n_hidden):\n",
    "        super(RBM, self).__init__()\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        self.W = nn.Parameter(torch.randn(n_visible, n_hidden))\n",
    "        self.b = nn.Parameter(torch.randn(n_visible))\n",
    "        self.c = nn.Parameter(torch.randn(n_hidden))\n",
    "\n",
    "    def energy(self, v, h):\n",
    "        v_self_energy = - torch.matmul(v, self.b)\n",
    "        h_self_energy = - torch.matmul(h, self.c)\n",
    "        cross_energy = - torch.matmul(v, torch.matmul(self.W, h.t()))\n",
    "        return v_self_energy + h_self_energy + cross_energy\n",
    "\n",
    "    def forward(self, v):\n",
    "        h = torch.sigmoid(F.linear(v, self.W.t(), self.c))\n",
    "        return h, torch.sigmoid(F.linear(h, self.W, self.b))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
